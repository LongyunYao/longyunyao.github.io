<!DOCTYPE html>


<html lang="en">


<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="龙云尧的小角落" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Python网络爬虫学习 |  剑阁
  </title>
  <meta name="generator" content="hexo-theme-ayer">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  <link rel="stylesheet" href="/dist/main.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Shen-Yu/cdn/css/remixicon.min.css">
  <link rel="stylesheet" href="/css/custom.css">
  
  <script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
  
  

  

<link rel="alternate" href="/atom.xml" title="剑阁" type="application/atom+xml">
</head>

</html>

<body>
  <div id="app">
    
      <canvas class="fireworks"></canvas>
      <style>
        .fireworks {
          position: fixed;
          left: 0;
          top: 0;
          z-index: 99999;
          pointer-events: none;
        }
      </style>
      
      
    <main class="content on">
      <section class="outer">
  <article id="post-Python网络爬虫学习" class="article article-type-post" itemscope itemprop="blogPost" data-scroll-reveal>
  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Python网络爬虫学习
</h1>
 

    </header>
     
    <div class="article-meta">
      <a href="/2017/05/17/Python网络爬虫学习/" class="article-date">
  <time datetime="2017-05-17T12:46:00.000Z" itemprop="datePublished">2017-05-17</time>
</a> 
  <div class="article-category">
    <a class="article-category-link" href="/categories/Python/">Python</a>
  </div>
  
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> Word count:</span>
            <span class="post-count">2.9k</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> Reading time≈</span>
            <span class="post-count">12 min</span>
        </span>
    </span>
</div>
 
    </div>
      
    <div class="tocbot"></div>




  
    <div class="article-entry" itemprop="articleBody">
       
  <p><strong>龙云尧个人博客，转载请注明出处</strong></p>
<p><em>初步了解网络爬虫的工具使用和代码编写</em></p>
<p>学习地址见<a href="http://study.163.com/course/courseMain.htm?courseId=1003285002" target="_blank" rel="noopener"><code>网易云课堂《Python网络实战》</code></a></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p><strong>工具</strong></p>
<p>1.Python编辑工具</p>
<p>实验中使用到的Python工具为<a href="https://www.continuum.io/downloads/" target="_blank" rel="noopener"><code>Anaconda</code></a>，工具的安装参照<a href="http://python.jobbole.com/86236/" target="_blank" rel="noopener"><code>Anaconda使用总结</code></a>（Linux下）以及<a href="http://blog.csdn.net/u012675539/article/details/46974217" target="_blank" rel="noopener"><code>Python科学计算的瑞士军刀——Anaconda 安装与配置</code></a>（windows下）相关教程。</p>
<p>在视频教学过程中，讲师也会有一点安装指导。</p>
<p>初学过程中推荐使用<code>Jupyter notebook</code>工具在浏览器中编辑，这样可以每次只执行几行函数，而不用一次从头到尾执行完毕。调试完成以后，可以在<code>Spyder</code>中一次运行。</p>
<p><code>Jupyter notebook</code>工具中，ctrl+enter表示执行当前cell的代码，alt+enter表示新建一个cell，其他的在本次实验中用不到。</p>
<p>2.辅助工具</p>
<p>使用<code>Chrome</code>辅助元素选择。需要对Chrome的<code>开发者模式</code>有较多的使用经验。</p>
<p>不过在视频中，讲师会反复示范怎么使用Chrome的开发者模式，所以使用起来不必太担心。</p>
<p><strong>知识储备</strong></p>
<p>1.语法</p>
<p>基本的Python语法知识可以参照<a href="http://www.runoob.com/python/python-basic-syntax.html" target="_blank" rel="noopener">Python 基础语法</a>（<strong>推荐</strong>）和<a href="http://www.cnblogs.com/toutou/p/4774284.html" target="_blank" rel="noopener">Python基本语法，python入门到精通[二]</a>（页面很low）</p>
<p><strong>注：<a href="http://www.runoob.com/python" target="_blank" rel="noopener">runoob.com</a>是一个好网站</strong></p>
<p>在语法和知识结构上，Python的概念和C++/Java这类面向对象型语言很相似，比如类似的对象概念.</p>
<p>比如类似于数组的列表(List)，类似于map的字典(dictdict)。其他部分自行体会.</p>
<p>因为本次教学课程中，实验较为简单，所以我其实也只是对Python有一个基本的了解。</p>
<p>2.工具使用</p>
<p>BeautifulSoap的使用教程参见<a href="http://cuiqingcai.com/1319.html" target="_blank" rel="noopener"><code>Python爬虫利器二之Beautiful Soup的用法</code></a></p>
<p>在本次实验中，网络爬虫需要对爬取的网页进行解析，故而不可避免的需要使用到html的相关知识。不过难度不大，一边实验一边回忆都已经足够了。</p>
<p>在实验中使用了BeautifulSoup工具能够很方便的将抓取的网页解析成一个文档树。然后我们就可以对这个文档树进行select，选择出特定的标签，进而分析出我们想要的信息。</p>
<p>举个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests <span class="comment"># 导入工具包</span></span><br><span class="line">artibody_url = <span class="string">'http://news.sina.com.cn/o/2017-04-18/doc-ifyeimzx6745829.shtml'</span></span><br><span class="line">artibody_res = requests.get(artibody_url) <span class="comment"># 模仿浏览器，使用get方法获取url指向的网页资源</span></span><br><span class="line">artibody_res.encoding = <span class="string">'utf-8'</span> <span class="comment"># 设置编码，否则抓取的文档会出现乱码</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup <span class="comment"># 从bs4中导入BeautifulSoap包</span></span><br><span class="line">artibody_soup = BeautifulSoup(artibody_res.text, <span class="string">'html.parser'</span>) <span class="comment"># 将抓取的网页扔进BeautifulSoap生成一个文档树</span></span><br><span class="line">artibody_div = artibody_soup.select(<span class="string">'#artibody p'</span>)[<span class="number">1</span>:<span class="number">-2</span>] <span class="comment"># 使用select方法获取想要的内容</span></span><br><span class="line"><span class="comment"># select中内容的使用和css的选择器类似，id使用'#xxx'， 类使用'.xxx'，普通标签使用'p'，另外还可以有子代选择器'body div #artibody p'</span></span><br></pre></td></tr></table></figure>

<p>3.<strong>本篇博客系个人学习所总结的知识，如果有什么概念或者其他错误，欢迎喷。但是不小心对你们造成误导，那就概不负责了2333</strong></p>
<p>##正题</p>
<h3 id="课程知识总结"><a href="#课程知识总结" class="headerlink" title="课程知识总结"></a>课程知识总结</h3><p>将这个部分写在最前面，是为了在课程开始之前就对整个课程的目的，以及coding过程中，每一步的目的有所了解。避免盲目跟着打代码，而不知道整个项目目的。</p>
<p>本课程实现了从网易新闻网页中抓取新闻信息，封装成结构化数据的过程。</p>
<p>课程一共18讲，每一讲2-10分钟不等，一般为5分钟。</p>
<ul>
<li>第1-3讲，为课程入门，大致介绍课程目的，对Python编写网络爬虫进行初步介绍。</li>
<li>第4讲，实现模拟浏览器，使用get方法获取网页信息的方法。</li>
<li>第5-6讲，介绍BeautifulSoap，介绍基本使用方法</li>
<li>第7-16讲，利用BeautifulSoap构造的文档树剖析整个网页，并且通过网页一步一步获取”title”(标题), “newssource”(原标题), “date”(发稿时间), “article”(新闻主题), “article”(编辑), “comments”(评论数)。</li>
<li>第17讲，函数封装指导</li>
<li>第18讲，将前17章中所实现的功能封装成一个函数，最终实现输入一个网页，返回一个封装好的结构化数据。</li>
</ul>
<h3 id="代码解释"><a href="#代码解释" class="headerlink" title="代码解释"></a>代码解释</h3><p><strong>1.requests获取网页信息</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入requests包</span></span><br><span class="line"><span class="keyword">import</span> requests </span><br><span class="line">artibody_url = <span class="string">'http://news.sina.com.cn/o/2017-04-18/doc-ifyeimzx6745829.shtml'</span></span><br><span class="line"><span class="comment"># 模仿浏览器发送一个get请求，获取链接指向的网页，将获取的数据存进artibody_res</span></span><br><span class="line">artibody_res = requests.get(artibody_url)</span><br><span class="line"><span class="comment"># 设置编码，以免乱码</span></span><br><span class="line">artibody_res.encoding = <span class="string">'utf-8'</span></span><br><span class="line"><span class="comment"># 打印text</span></span><br><span class="line">print(artibody_res.text)</span><br></pre></td></tr></table></figure>

<p><strong>2.利用BeautifulSoap将网页装进文档树</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从bs4中导入BeautifulSoup数据</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="comment"># 选择解析器为Python标准库(html.parser)，如果不设置就会有warnning</span></span><br><span class="line">artibody_soup = BeautifulSoup(artibody_res.text, <span class="string">'html.parser'</span>)</span><br><span class="line"><span class="comment"># 调用BeautifulSoap中的select方法进行，[1:-2]表示选择从第1个元素到倒数第二个元素（Python从0开始计数）</span></span><br><span class="line">artibody_div = artibody_soup.select(<span class="string">'#artibody p'</span>)[<span class="number">1</span>:<span class="number">-2</span>]</span><br><span class="line">print(artibody_div)</span><br></pre></td></tr></table></figure>

<p><strong>3.获取文本信息</strong></p>
<p>strip函数的使用可以参考<a href="http://www.jb51.net/article/37287.htm" target="_blank" rel="noopener">python strip()函数 介绍</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 构建一个List，用于存放文本</span></span><br><span class="line">article = []</span><br><span class="line"><span class="comment"># for循环，记得for语句最后有一个':'（注，Python没有括号，而是以缩进代替）</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> artibody_div:</span><br><span class="line">    <span class="comment"># 调用append方法，将text一个一个加入list，调用strip()是为了去掉空白字符</span></span><br><span class="line">    article.append(p.text.strip())</span><br><span class="line">print(article)</span><br></pre></td></tr></table></figure>

<p><strong>4.文本合并</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用join方法，两article中的元素全部合并，原本List中不同的元素之间使用' '隔开，换成'\n'也可</span></span><br><span class="line"><span class="comment">#只不过Juphter Notebook会直接将'\n'显示出来而已</span></span><br><span class="line"><span class="string">' '</span>.join(article)</span><br></pre></td></tr></table></figure>

<p><strong>5.一行实现文本合并</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不用解释了吧</span></span><br><span class="line"><span class="string">' '</span>.join([p.text.strip() <span class="keyword">for</span> p <span class="keyword">in</span> artibody_soup.select(<span class="string">'#artibody p'</span>)[<span class="number">1</span>:<span class="number">-2</span>]])</span><br></pre></td></tr></table></figure>

<p><strong>6.编辑提取</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 调用lstrip左切除</span></span><br><span class="line">artibody_editor = artibody_soup.select(<span class="string">'.article-editor'</span>)[<span class="number">0</span>].text.lstrip(<span class="string">'责任编辑：'</span>)</span><br><span class="line">print(artibody_editor)</span><br></pre></td></tr></table></figure>

<p><strong>7.title获取</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">artibody_title = artibody_soup.select(<span class="string">'title'</span>)[<span class="number">0</span>].text</span><br><span class="line">print(artibody_title)</span><br></pre></td></tr></table></figure>

<p><strong>8.引用获取</strong></p>
<p>contents的使用请继续参照开头提到的文章<a href="http://cuiqingcai.com/1319.html" target="_blank" rel="noopener"><code>Python爬虫利器二之Beautiful Soup的用法</code></a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在较为复杂的层级结构中，调用contents获得其子节点</span></span><br><span class="line">artibody_p = artibody_div.select(<span class="string">'p'</span>)[<span class="number">0</span>].contents[<span class="number">0</span>].strip()</span><br><span class="line">print(artibody_p)</span><br></pre></td></tr></table></figure>

<p><strong>9.日期获取</strong></p>
<p>关于datetime的使用，参见<a href="http://www.cnblogs.com/snow-backup/p/5063665.html" target="_blank" rel="noopener">python 常用 time, datetime处理</a>。</p>
<p>（其实只要只要strptime和strftime的用法，在本次实验就足够了。）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">artibody_time = artibody_soup.select(<span class="string">'.time-source'</span>)[<span class="number">0</span>].contents[<span class="number">0</span>].strip()</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="comment"># 使用datetime进行日期获取，strptime表示将str转换成时间</span></span><br><span class="line">dt = datetime.strptime(artibody_time, <span class="string">'%Y年%m月%d日%H:%M'</span>)</span><br><span class="line"><span class="comment"># strftime表示将时间转换成文字</span></span><br><span class="line">print(dt.strftime(<span class="string">'%Y-%m-%d %H:%M'</span>))</span><br></pre></td></tr></table></figure>

<p><strong>10.来源获取</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不解释</span></span><br><span class="line">artibody_from = artibody_soup.select(<span class="string">'.time-source span a'</span>)[<span class="number">0</span>].text</span><br><span class="line">print(artibody_from)</span><br></pre></td></tr></table></figure>

<p><strong>11.评论数获取</strong></p>
<p>在课程中，最难抓的也就是这货了。因为使用的是js从后台获取数据，所以不能直接从静态网页抓取。</p>
<p>下面代码就展示了，明明使用了正确的定位，但是抓取不到数值的情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">artibody_commentCount = artibody_soup.select(&apos;.page-tool-i&apos;)</span><br><span class="line">print(artibody_commentCount)</span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[&lt;span class=&quot;page-tool-i page-tool-s&quot; title=&quot;分享&quot;&gt;</span><br><span class="line">&lt;a href=&quot;javascript:;&quot; id=&quot;shareArticleButton&quot; onclick=&quot;_S_uaTrack(&apos;index_news_content&apos;, &apos;other_click&apos;);&quot;&gt;分享&lt;/a&gt;</span><br><span class="line">&lt;/span&gt;, &lt;span class=&quot;page-tool-i page-tool-c page-tool-share&quot; title=&quot;评论&quot;&gt;</span><br><span class="line">&lt;span id=&quot;commentCount1&quot;&gt;&lt;/span&gt;</span><br><span class="line">&lt;a href=&quot;javascript:;&quot; suda-uatrack=&quot;key=index_news_content&amp;amp;value=comment_click&quot;&gt;&lt;/a&gt;</span><br><span class="line">&lt;/span&gt;, &lt;span class=&quot;page-tool-i page-tool-s&quot; title=&quot;分享&quot;&gt;</span><br><span class="line">&lt;a href=&quot;javascript:;&quot; id=&quot;shareArticleButton2&quot; onclick=&quot;_S_uaTrack(&apos;index_news_content&apos;, &apos;other_roll_click&apos;);&quot;&gt;分享&lt;/a&gt;</span><br><span class="line">&lt;/span&gt;, &lt;span class=&quot;page-tool-i page-tool-c page-tool-share&quot; id=&quot;pageToolShare&quot; title=&quot;评论&quot;&gt;</span><br><span class="line">&lt;a href=&quot;javascript:;&quot; suda-uatrack=&quot;key=index_news_content&amp;amp;value=comment_roll_click&quot;&gt;&lt;/a&gt;</span><br><span class="line">&lt;span id=&quot;commentCount1M&quot;&gt;&lt;/span&gt;</span><br><span class="line">&lt;/span&gt;]</span><br></pre></td></tr></table></figure>

<p>只有span标签，而没有任何a标签。</p>
<p>所以我们只能从仿照js抓取数据了。不要问我那个老师是怎么知道是哪个js文件的= =，我也觉得很神奇。</p>
<p>抓取过程中可以用一点小技巧。</p>
<p>在网页加载过程中盯着评论数。</p>
<p><img src="https://cloud.githubusercontent.com/assets/18045191/25130907/7cd4cf38-2476-11e7-82fe-2faad44f5885.PNG" alt="未加载出来"></p>
<p>在评论加载出来之后，立即停止Chrome中开发者模式下控制台的监控。这样从后向前找会轻松一点（虽然还是需要寻找很久）。</p>
<p><img src="https://cloud.githubusercontent.com/assets/18045191/25130906/7cc85c44-2476-11e7-8132-f0b72b7a09e4.PNG" alt="加载出来"></p>
<p>寻找的过程中好好利用控制台的preview功能。</p>
<p><img src="https://cloud.githubusercontent.com/assets/18045191/25130889/6f905068-2476-11e7-80d6-39ef6e4b2e4b.png" alt="preview功能"></p>
<p>抓取过程中，代码如下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">comment_url = <span class="string">'http://comment5.news.sina.com.cn/page/info?version=1&amp;format=js&amp;channel=gn&amp;newsid=comos-fyeimzx6745829&amp;group=&amp;compress=0&amp;ie=utf-8&amp;oe=utf-8&amp;page=1&amp;page_size=20'</span></span><br><span class="line">comment_res = requests.get(comment_url)</span><br><span class="line">comment_res.encoding = <span class="string">'utf-8'</span></span><br><span class="line">print(comment_res.text)</span><br></pre></td></tr></table></figure>

<p>然后你就能够抓到如下结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">var data=&#123;&quot;result&quot;: &#123;&quot;status&quot;: &#123;&quot;msg&quot;: &quot;&quot;, &quot;code&quot;: 0&#125;, &quot;count&quot;: &#123;&quot;qreply&quot;: 10065, &quot;total&quot;: 10756, &quot;show&quot;: 200&#125;, &quot;replydict&quot;: ...中间省去真·1w字..., &quot;agree&quot;: &quot;251&quot;, &quot;channel&quot;: &quot;gn&quot;, &quot;uid&quot;: &quot;5121097321&quot;&#125;]&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>将js返回的这一段数据，使用json存放起来。</p>
<p>json的基本操作参见<a href="http://www.cnblogs.com/kaituorensheng/p/3877382.html" target="_blank" rel="noopener">python解析json</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">jd = json.loads(comment_res.text.strip(<span class="string">'var data='</span>))</span><br><span class="line"><span class="comment"># 获取jd下'result'标签中‘count'标签中’total‘内容</span></span><br><span class="line">jd[<span class="string">'result'</span>][<span class="string">'count'</span>][<span class="string">'total'</span>]</span><br></pre></td></tr></table></figure>

<p>到这里评论数的获取就结束了，有点麻烦们也有点蛋疼。</p>
<p><strong>12.获取newsid</strong></p>
<p>这一步获取newsid能够让我们在后面实现批量导入。</p>
<p>关于正则表示式的使用，参见<a href="http://www.runoob.com/python/python-reg-expressions.html" target="_blank" rel="noopener">Python正则表达式</a>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 有两种实现方法，第一种，先split，然后去头去尾提取出来就是了</span></span><br><span class="line"><span class="comment">#artibody_url.split('/')[-1].rstrip('.shtml')</span></span><br><span class="line"><span class="comment"># newsid=comos-fyeimzx6745829</span></span><br><span class="line"><span class="comment">#news_id = artibody_url.split('/')[-1].lstrip('doc-i').rstrip('.shtml')</span></span><br><span class="line"><span class="comment">#另一种是使用正则表达式</span></span><br><span class="line"><span class="comment"># group(1)表示匹配的字符串， group(0)会将整个字符串返回回来</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">news_id = re.search(<span class="string">'doc-i(.*).shtml'</span>, artibody_url).group(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p><strong>13.使用newsid</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将newsis填入form_comment_url的括号内</span></span><br><span class="line">form_comment_url = <span class="string">'http://comment5.news.sina.com.cn/page/info?version=1&amp;\</span></span><br><span class="line"><span class="string">format=js&amp;channel=gn&amp;newsid=comos-&#123;&#125;&amp;group=&amp;compress=0&amp;ie=utf-8&amp;oe=utf-8&amp;page=1&amp;page_size=20'</span></span><br><span class="line">form_comment_url.format(news_id)</span><br></pre></td></tr></table></figure>

<p><strong>14.封装函数</strong></p>
<p>封装函数之后，我们就能够实现，传入一个新闻的网址，就获取这个新闻的评论数的功能了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">artibody_url = <span class="string">'http://news.sina.com.cn/o/2017-04-18/doc-ifyeimzx6745829.shtml'</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getCommentCounts</span><span class="params">(news_url)</span>:</span></span><br><span class="line">    news_id = re.search(<span class="string">'doc-i(.*).shtml'</span>, news_url).group(<span class="number">1</span>)</span><br><span class="line">    comments = requests.get(form_comment_url.format(news_id))</span><br><span class="line">    jd = json.loads(comments.text.lstrip(<span class="string">'var data='</span>))</span><br><span class="line">    <span class="keyword">return</span> jd[<span class="string">'result'</span>][<span class="string">'count'</span>][<span class="string">'total'</span>]</span><br></pre></td></tr></table></figure>

<p><strong>15.整体封装</strong></p>
<p>前面步骤全部走了一遍之后，我们就可以将它们封装起来，称为一个函数了。</p>
<p>通过这一步，我们可以就可以把<code>news.sina.com.cn/china</code>中所有的href获取下来，然后逐一传入这个函数，就能够得到每一条新闻的结构化数据了。剩下的任务就是看我们怎么使用咯。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getNewsDetail</span><span class="params">(newsurl)</span>:</span></span><br><span class="line">    result = &#123;&#125;</span><br><span class="line">    res = requests.get(newsurl)</span><br><span class="line">    res.encoding = <span class="string">'utf-8'</span></span><br><span class="line">    soup = BeautifulSoup(res.text, <span class="string">'html.parser'</span>)</span><br><span class="line">    result[<span class="string">'title'</span>] = soup.select(<span class="string">'title'</span>)[<span class="number">0</span>].text</span><br><span class="line">    result[<span class="string">'newssource'</span>] = soup.select(<span class="string">'p'</span>)[<span class="number">0</span>].contents[<span class="number">0</span>].strip()</span><br><span class="line">    artibody_time = soup.select(<span class="string">'.time-source'</span>)[<span class="number">0</span>].contents[<span class="number">0</span>].strip()</span><br><span class="line">    result[<span class="string">'dt'</span>] = datetime.strptime(artibody_time, <span class="string">'%Y年%m月%d日%H:%M'</span>)</span><br><span class="line">    result[<span class="string">'article'</span>] = <span class="string">' '</span>.join([p.text.strip() <span class="keyword">for</span> p <span class="keyword">in</span> soup.select(<span class="string">'#artibody p'</span>)[<span class="number">1</span>:<span class="number">-2</span>]])</span><br><span class="line">    result[<span class="string">'editor'</span>] = soup.select(<span class="string">'.article-editor'</span>)[<span class="number">0</span>].text.lstrip(<span class="string">'责任编辑：'</span>)</span><br><span class="line">    result[<span class="string">'comments'</span>] = getCommentCounts(newsurl)</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>

<p>整个<code>Python网络爬虫实战</code>课程到这里也就结束了。<code>丘祐玮</code>讲师讲课比较细致，整个课程浅显易懂，对于有JS基础或者java基础或者C++基础或者Matlab基础的人来说，应该不难。</p>
 
      <!-- reward -->
      
      <div id="reward-btn">
        Donate
      </div>
      
    </div>
    

    <!-- copyright -->
    
    <div class="declare">
      <ul class="post-copyright">
        <li>
          <i class="ri-copyright-line"></i>
          <strong>Copyright： </strong>
          Copyright is owned by the author. For commercial reprints, please contact the author for authorization. For non-commercial reprints, please indicate the source.
        </li>
      </ul>
    </div>
    
    <footer class="article-footer">
       
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        Share with
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://yaoyl.cn/2017/05/17/Python网络爬虫学习/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>  
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Python/">Python</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/爬虫/">爬虫</a></li></ul>

    </footer>
  </div>

   
  <nav class="article-nav">
    
      <a href="/2017/05/18/第一次爬虫实验代码及运行结果（html文本进行适当删除以压缩版面）/" class="article-nav-link">
        <strong class="article-nav-caption">last text</strong>
        <div class="article-nav-title">
          
            第一次爬虫实验代码及运行结果（html文本进行适当删除以压缩版面）
          
        </div>
      </a>
    
    
      <a href="/2017/05/12/OpenGL学习笔记（九）/" class="article-nav-link">
        <strong class="article-nav-caption">next text</strong>
        <div class="article-nav-title">OpenGL学习笔记（九）</div>
      </a>
    
  </nav>

   
<!-- valine评论 -->
<div id="vcomments-box">
  <div id="vcomments"></div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script>
<script>
  new Valine({
    el: "#vcomments",
    app_id: "qkDBSm4o58WMY10dnnN3G3DG-gzGzoHsz",
    app_key: "A3yKU51qb7l8hBysTQRJG0Xa",
    path: window.location.pathname,
    avatar: "monsterid",
    placeholder: "给我的文章加点评论吧~",
    recordIP: true,
  });
  const infoEle = document.querySelector("#vcomments .info");
  if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
    infoEle.childNodes.forEach(function (item) {
      item.parentNode.removeChild(item);
    });
  }
</script>
<style>
  #vcomments-box {
    padding: 5px 30px;
  }

  @media screen and (max-width: 800px) {
    #vcomments-box {
      padding: 5px 0px;
    }
  }

  #vcomments-box #vcomments {
    background-color: #fff;
  }

  .v .vlist .vcard .vh {
    padding-right: 20px;
  }

  .v .vlist .vcard {
    padding-left: 10px;
  }
</style>

 
     
</article>

</section>
      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2017-2020
        <i class="ri-heart-fill heart_icon"></i> Yunyao Long
      </li>
    </ul>
    <ul>
      <li>
        
        
        
        Powered by <a href="https://hexo.io" target="_blank">Hexo</a>
        <span class="division">|</span>
        Theme - <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span></span>
        
      </li>
    </ul>
    <ul>
      
        <li>
          <a href="http://www.beian.miit.gov.cn/" target="_black">粤ICP备-17050867-1号</a>
        </li>
        
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src="https://v1.cnzz.com/z_stat.php?id=1279087554&amp;web_id=1279087554"></script>
        
      </li>
    </ul>
  </div>
</footer>
      <div class="float_btns">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

      </div>
    </main>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="剑阁"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search" title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <script>
      if (window.matchMedia("(max-width: 768px)").matches) {
        document.querySelector('.content').classList.remove('on');
        document.querySelector('.sidebar').classList.remove('on');
      }
    </script>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechatpay.png">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/lazyload.min.js"></script>
<!-- Tocbot -->

<script src="/js/tocbot.min.js"></script>
<script>
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer: 'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto'
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js"></script>
<script src="/dist/main.js"></script>
<!-- ImageViewer -->

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>

<!-- MathJax -->

<!-- Katex -->

<!-- busuanzi  -->

<script src="/js/busuanzi-2.3.pure.min.js"></script>

<!-- ClickLove -->

<!-- ClickBoom1 -->

<script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script>
<script src="/js/clickBoom1.js"></script>

<!-- ClickBoom2 -->

<!-- CodeCopy -->

<link rel="stylesheet" href="/css/clipboard.css">
<script src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>


<!-- CanvasBackground -->


    
    <div id="music">
    
    
    
    <iframe frameborder="no" border="1" marginwidth="0" marginheight="0" width="200" height="86" src="//music.163.com/outchain/player?type=2&id=447279413&auto=1&height=66"></iframe>
</div>

<style>
    #music {
        position: fixed;
        right: 15px;
        bottom: 0;
        z-index: 998;
    }
</style>
    
  </div>
</body>

</html>